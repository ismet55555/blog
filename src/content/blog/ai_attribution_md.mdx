---
title: 'AI_ATTRIBUTION.md: A Standard for Tracking Creative Control in Human-AI Programming Collaboration'
description: 'A single markdown file that tracks creative control in AI-assisted software development. For debugging, portfolios, and honest attribution.'
pubDate: 'Feb 25 2026'
tags: ['AI', 'software-development', 'attribution', 'documentation', 'open-source', 'collaboration', 'ai-ethics']
draft: true
tech: true
aiHelp: [
  'Literature research for similar concepts and frameworks - Claude, ChatGPT (research)',
  'Spelling, grammar, structure, flow, accuracy suggestions - Claude',
  'Tables and formatting - Claude',
  'General post-hoc review and rewording - Claude',
  'Generating images - ChatGPT',
]
---
import Figure from '../../components/Figure.astro'
import Tag from '../../components/Tag.astro'
import ViewCodeButton from '../../components/ViewCodeButton.astro'
import SectionDividerDash from '../../components/SectionDividerDash.astro'
import tba from '../../images/tba.png';
import legoHands from '../../images/ai_attribution/legoHands.png';

## Table of Contents


## Introduction


If you have been actively programming something while using AI tools like [Anthropic's Claude Code](https://code.claude.com/docs/en/overview)
or [OpenAI's Cortex](https://openai.com/codex/) you might have wondered 
is this specific code, idea, or direction human-made or did AI make this?

Typically, our first instinct is to think in terms of [git blame history](https://www.atlassian.com/git/tutorials/inspecting-a-repository/git-blame).
That is, we think in terms of raw lines of code and characters added.
Did the AI tool or an actual person write this line of code?

<Figure
  src={legoHands}
  caption="TODO"
  url="TODO.com"
  width= '4/5'
  class= 'w-4/5 mx-auto border border-3 border-accentColor'
/>

However consider this: if an AI generates 200 lines of boilerplate code that you 
carefully reviewed and modified, *versus* you writing 50 lines of a novel algorithm 
after rejecting three AI suggestions ... which represents more of "your work"?

Programming software is just so much more than the actual typed characters
in a file. When we write software we might consider things like:

- **Problem definition and architecture decisions** - What are we building and how should it be structured?
- **Creative control and decision-making** - Who chose this approach over alternatives?
- **Domain expertise and constraints** - Understanding field-specific requirements (security, performance, regulatory compliance)
- **Code review and quality judgment** - Evaluating whether the solution is actually good/maintainable
- **Future-proofing and extensibility** - Designing for change and growth beyond the immediate need

An AI tool might draft the implementation, but you define the problem, choose the approach, 
and vouch for the result. So how do we capture who actually had creative control?
What contribution came from the developer and what was generated by AI?

In this article, I'm going to attempt to outline this core problem of AI attribution,
why it matters, and what's currently being done about it. Then I will give you my proposed
practical solution to this problem.


<SectionDividerDash />

## Why AI Attribution Matters

Attribution solves four general problems you'll hit whether you track
contributions or not.

#### Debugging When Things Break

A bug surfaces six months after deployment. Was this AI-generated boilerplate you adapted, or
code you wrote from scratch? Each scenario changes your debugging approach. AI-generated code
might have assumptions you never questioned. Without attribution records, you're
reverse-engineering your own thought process instead of fixing the bug.

The [Linux kernel community](https://kernel.org/doc/html/next/process/coding-assistants.html)
now requires `Assisted-by:` tags in commits because maintainers need to know code provenance
when things break. It's operational infrastructure, not paperwork.

#### Documenting Invisible Work

Git commits show lines added, not creative vision. They don't capture the three AI suggestions
you rejected, the hours hand-tuning constants, or the architectural decisions that made
everything else possible. Design decisions, problem framing, rejecting bad approachesâ€”this is
the work that actually matters, and none of it shows up in your codebase. An attribution log
documents it.

#### Building Credible Portfolios

Vague ambiguity about AI involvement hurts you. People assume the worst. But specific
attribution ("AI scaffolded the configuration; I designed the architecture and wrote the core
algorithm") demonstrates exactly what you're capable of.

[Research shows](https://dl.acm.org/doi/full/10.1145/3706598.3713522) people assign less
credit to AI-assisted work even when you controlled all the decisions. The fix isn't hiding AI
involvement, it's being precise about creative control.

#### Accounting for Memory Decay

Six months from now, you won't remember which parts were AI-assisted. Your brain merges the
collaboration into "I built this." Then someone asks for details during a code review, and you
realize you don't actually know.

This isn't a personal failing, it's how [human memory works in collaborative contexts](https://www.researchgate.net/publication/395526725_The_AI_Memory_Gap_Users_Misremember_What_They_Created_With_AI_or_Without).
Attribution logs remember what you'll forget.

<SectionDividerDash />

## Current AI Attribution Landscape

AI transparency systems already exist, but they're solving different problems than the one
developers face daily.

### The Transparency Stack

Think of AI transparency as layers, each answering a different question:

**Layer 1: Binary Disclosure**  
"Was AI used?" Academic publishers like [Nature](https://www.nature.com/nature-portfolio/editorial-policies/ai)
and [SAGE](https://www.sagepub.com/journals/publication-ethics-policies/artificial-intelligence-policy)
require this, but the rules vary wildly. Some accept undisclosed AI for copy editing, others
require statements for any use. The [International Committee of Medical Journal Editors](https://www.icmje.org/recommendations/browse/roles-and-responsibilities/defining-the-role-of-authors-and-contributors.html)
states AI can't be an author but offers no standard format for documenting human
responsibility.

**Layer 2: Provenance & Integrity**  
"Can we verify this file's history?" [C2PA](https://c2pa.org/) and
[IPTC Digital Source Type](https://cv.iptc.org/newscodes/digitalsourcetype/) answer this with
cryptographic signatures. They tell you an image came from Photoshop and was AI-edited, but
not who controlled the creative decisions.

**Layer 3: Supply Chain (AI-BOM)**  
"What models and datasets were involved?" Standards like
[CycloneDX ML-BOM](https://cyclonedx.org/capabilities/mlbom/) and
[SPDX 3.x](https://spdx.github.io/spdx-spec/v3.0/) document ML components, similar to
software bill of materials. They inventory dependencies, not collaboration.

**Layer 4: Attribution Statements**  
"How should we describe AI involvement?" [IBM's AI Attribution Toolkit](https://research.ibm.com/blog/AI-attribution-toolkit)
generates human-readable statements about proportion, type, and review levelâ€”but only for
finished artifacts, not ongoing workflows.

**Layer 5: Collaboration Semantics**  
"Who exercised creative control during the work?" *This is where `AI_ATTRIBUTION.md` operates.*

### What's Missing From Current Systems

Here's what existing approaches don't capture:

| They Tell You | They Don't Tell You |
|---------------|---------------------|
| AI was used | Whether AI suggested the architecture or just formatted code |
| The work is copyrightable ([U.S. Copyright Office guidance](https://www.copyright.gov/ai/)) | Whether you designed the algorithm or adopted AI's first suggestion |
| The file came from tool X | How creative control shifted during development |
| 30% was AI-generated | If that 30% was boilerplate you reviewed or core logic you accepted blindly |

Open source communities are improvising their own solutions. The
[Linux kernel requires `Assisted-by:` commit tags](https://kernel.org/doc/html//next/process/coding-assistants.html)
with tool and model version. [Gentoo banned AI contributions entirely](https://wiki.gentoo.org/wiki/Project:Council/AI_policy).
[Fedora requires disclosure](https://docs.fedoraproject.org/en-US/council/policy/ai-contribution-policy/) but no
standard format. Everyone knows they need somethingâ€”nobody agrees on what.

### The Gap

[Research on AI attribution in HCI contexts](https://dl.acm.org/doi/full/10.1145/3706598.3713522) 
shows people struggle to consistently judge credit for AI-assisted work.
They also can't reliably remember which ideas came from AI after time
passes.

The [EU AI Act](https://artificialintelligenceact.eu/the-act/)
requires transparency labels, and [China mandates labeling for AI-generated content](https://harris-sliwoski.com/chinalawblog/chinas-new-ai-labeling-rules-what-every-china-business-needs-to-know/),
but neither specifies how to document internal creative control.

None of these systems track creative control at the task level, chronologically, as work
happens. That's the operational question developers actually need answered for debugging,
code review, and taking responsibility for their work.

That's what `AI_ATTRIBUTION.md` provides.


<SectionDividerDash />


## `AI_ATTRIBUTION.md`

**[`AI_ATTRIBUTION.md`](https://github.com/ismet55555/ai-attribution) is a single markdown
file that lives in your project repository. It's a structured log that tracks who had
creative control over specific workâ€”you or the AI tool.**

### The Core Concept: Six Levels of Creative Control

Instead of simply asking if AI was used or not, or just measuring "what percentage was AI,"
the framework uses six involvement levels that capture who made the decisions:

|   | Level | Decision Test |
|---|-------|---------------|
| ðŸ”´ | **GENERATED** | AI created it autonomously; you accepted without meaningful changes |
| ðŸŸ  | **ASSISTED** | AI provided substantial implementation; you guided direction and made key decisions |
| ðŸŸ¡ | **GUIDED** | You directed the approach; AI helped with specific tasks or suggestions |
| ðŸŸ¢ | **INFORMED** | You did the work; AI provided reference material or answered questions |
| ðŸ”µ | **REVIEWED** | You wrote it; AI reviewed and you considered its feedback |
| âšª | **NONE** | No AI involvement |

The key insight: these aren't about line counts. They're about who controlled the creative
decisions. For example, you can reject a dozen AI suggestions and write 10 lines yourself,
that's `GUIDED` or `INFORMED`, not `GENERATED`.

### How It Works in Practice

Each entry in your log captures:

- **What was built** - Scope tags like `code`, `design`, `docs`, `tests`.
- **Involvement level** - One of the six levels listed above.
- **Which tool** - The AI model name and version.
- **Optional context** - What you decided, what you rejected, why you chose this approach.

Here are a few real example from one of my game development projects.
*Click to expand.*


<details>
<summary><p style="display: inline;">Attribution Log Entry Example 1</p></summary>
        
```markdown title="AI_ATTRIBUTION.md"
### [2026-02-22] â€” Burst-then-coast bullet dynamic [ðŸŸ¡ `GUIDED` â€” design, code]

**Human:** Asked about interesting bullet movement dynamics for 2D games.
Chose burst-then-coast from four options AI presented. Implemented
`BurstSpeed` and `CruiseSpeed` components and the lerp-based deceleration
independently after AI explained the concept.

**AI (Claude):** Presented four bullet dynamic options (acceleration,
burst-then-coast, sine wave, deceleration) with descriptions. Explained
lerp-based deceleration in detail: how `f32::lerp()` works, why multiplying
by `delta_secs()` makes it frame-rate independent, what `.clamp(0.0, 1.0)`
guards against, and the relationship between the three config values
(`BULLET_BURST_SPEED`, `BULLET_CRUISE_SPEED`, `BULLET_SPEED_DECAY`).
Wrote implementation plan.

**Commits:** `["e0ee2cf"]`

**Notes:** Human chose the dynamic and did the implementation. AI's primary
contribution was explaining the lerp math and the burst/cruise/decay
parameter relationships.
```
</details>

<br/>

<details>
<summary><p style="display: inline;">Attribution Log Entry Example 2</p></summary>
        
```markdown title="AI_ATTRIBUTION.md"
### [2026-02-22] â€” Codebase review for easy wins [ðŸ”µ `INFORMED` â€” code]

**Human:** Asked for optimization and clarity improvements across the
project.

**AI (Claude):** Reviewed all source files and identified 10 issues: a bug
(`return` vs `continue` in bullet loop), unnecessary `Resource` derive on
`WallHit`, duplicated `MovingDirection`/`Size` types across modules,
duplicated wall collision logic, stale test system (`test_flicker_on_keypress`),
copy-paste comment errors, missing inspector registrations. Prioritized
the bug fix and deduplication as highest value.

**Commits:** `["50e2d34"]`

**Notes:** Human asked the question, AI identified issues. Implementation
of fixes is ongoing.
```
</details>

<br/>

<details>
<summary><p style="display: inline;">Attribution Log Entry Example 3</p></summary>
        
```markdown title="AI_ATTRIBUTION.md"
### [2026-02-17] â€” Centralized config module [ðŸŸ  `ASSISTED` â€” config, code]

**Human:** Decided to centralize all global constants into `src/config.rs`.
Chose the file location. Explicitly rejected local re-export convenience
aliases -- wanted `config::` prefix used directly at every call site.

**AI (Claude):** Created `src/config.rs` with all constants (window, camera,
level, player, logging). Updated `level.rs`, `camera.rs`, `main.rs`, and
`player.rs` to reference `config::` prefixed constants. Configured
`bevy::log::LogPlugin` with `config::LOG_LEVEL`.

**Commits:** uncommitted

**Notes:** Human made the architectural decision and style preference
(no re-exports). AI executed the extraction and migration across files.
```
</details>



### What This Solves

Remember those four problems from earlier? This file addresses each:

- **Debugging:** When the pathfinding bugs out, I know immediately that the core algorithm came
from AI but I modified obstacle avoidance. I know where to look.

- **Invisible work:** The log captures that I designed the movement architecture and rejected
approaches. That's nowhere in the git commits.

- **Credibility:** I can point to specific entries showing "I designed the state machine; AI
implemented physics based on my specs."

- **Memory:** Six months later, I don't need to reconstruct who decided what. It's written down.

### Three Format Options

The framework supports three log formats depending on your needs:

- **[Markdown](https://commonmark.org/)** - Human-readable, lives in your repo.
- **[JSONL](https://jsonlines.org/)** - Machine-parsable for tooling and analytics.
- **[TOON](https://toonformat.dev/)** - Token-optimized for including in AI context windows.

Most developers start with markdown and generate other formats when needed.

<Aside variant="tip">
  Get started using `AI_ATTRIBUTION.md` by following the instructions in the
  project's GitHub repository:
  <br/>
  [AI_ATTRIBUTION.md GitHub Repository Project](https://github.com/ismet55555/ai-attribution)
</Aside>

<SectionDividerDash />

## Conclusion

The AI attribution problem isn't going away. As AI tools become more capable, the question of
"who did what" becomes harder to answer and more important to document.

Binary disclosure doesn't cut it. Percentage metrics miss the point. Memory fails us all.

`AI_ATTRIBUTION.md` offers a third way: structured logging that captures creative control as
work happens. It's lightweight enough to actually use, specific enough to be meaningful, and
standardized enough to support tooling.

Imagine a future where code review tools automatically highlight AI-assisted sections and
portfolio sites generate contribution breakdowns from attribution logs. Hiring managers could
see not just what you built, but how you exercised creative control.
That future requires a standard.

This is my proposal for what that standard could be.

**Try it on your next project.** Even logging for a week will teach you something about how
you actually collaborate with AI. If it works, share it. If it doesn't, tell me why so we can
make it better.

The repository is at [github.com/ismet55555/ai-attribution](https://github.com/ismet55555/ai-attribution).
Contributions, feedback, and real-world examples are welcome.

We're building the tools that will define how humans and AI work together. Let's capture that
collaboration honestly.

<Figure
  src={tba}
  caption="TODO"
  url="TODO.com"
  width= '4/5'
  class= 'w-4/5 mx-auto border border-3 border-accentColor'
/>

> In an age of AI-assisted averages, creative control is what makes us outliers.

